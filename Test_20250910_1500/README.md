# WordCompass Model Testing Framework

This testing framework compares different OpenAI models to find the best one for your thesaurus application.

## ğŸ¯ What It Tests

- **Success Rate**: How often each model returns valid JSON
- **Response Time**: Speed of API calls
- **Quality**: Number and relevance of synonyms
- **Cost vs Performance**: Balance between model cost and results

## ğŸš€ Quick Start

1. **Install dependencies:**
   ```bash
   cd Test
   npm install
   ```

2. **Set up your API key:**
   ```bash
   # Copy your API key from the main project
   cp ../.env .env
   # Or edit Test/.env and add your key
   ```

3. **Run tests:**
   ```bash
   # Quick test (3 words, 2 scenarios per model)
   npm run test:quick
   
   # Detailed test (all words and scenarios)
   npm run test:detailed
   
   # Default (same as quick)
   npm test
   ```

## ğŸ“Š Models Tested

| Model | Cost | Description |
|-------|------|-------------|
| `gpt-4o-mini` | Low | Current model - fast and cheap |
| `gpt-3.5-turbo` | Low | Classic fast model |
| `gpt-4o` | Medium | Latest GPT-4, more capable |
| `gpt-4-turbo` | High | Most capable, expensive |

## ğŸ§ª Test Scenarios

The framework tests each model with:

- **15 different words** (easy, medium, hard difficulty)
- **5 different scenarios** (Modern Casual, Historical Formal, UK Academic, Creative Vivid, Rare Negative)
- **Various slider combinations** to test parameter adherence

## ğŸ“ˆ What You'll Get

- **Performance comparison table**
- **Success rate analysis**
- **Response time metrics**
- **Cost vs performance recommendations**
- **Detailed JSON report** saved to file

## ğŸ’¡ Example Output

```
ğŸš€ Running Quick Model Comparison Test

Testing gpt-4o-mini...
  âœ… happy (Modern Casual): 12 synonyms, 1847ms
  âœ… beautiful (Modern Casual): 14 synonyms, 1923ms
  âœ… smart (Historical Formal): 11 synonyms, 1756ms

ğŸ“Š Test Results Summary

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model           â”‚ Success Rateâ”‚ Avg Response Timeâ”‚ Avg Synonymsâ”‚ Cost Level â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-4o-mini     â”‚ 100.0%      â”‚ 1854ms          â”‚ 12          â”‚ low        â”‚
â”‚ gpt-3.5-turbo   â”‚ 100.0%      â”‚ 2103ms          â”‚ 11          â”‚ low        â”‚
â”‚ gpt-4o          â”‚ 100.0%      â”‚ 3245ms          â”‚ 13          â”‚ medium     â”‚
â”‚ gpt-4-turbo     â”‚ 100.0%      â”‚ 4567ms          â”‚ 14          â”‚ high       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ Recommendations:

ğŸ† Best Success Rate: gpt-4o-mini (100.0%)
âš¡ Fastest Response: gpt-4o-mini (1854ms)
âœ… Low-cost models perform well - consider staying with current model
```

## ğŸ”§ Customization

You can modify:
- **Test words** in `test-data.js`
- **Test scenarios** in `test-data.js`
- **Models to test** in `test-models.js`
- **Evaluation criteria** in the code

## ğŸ“ Output Files

- `test-results-[timestamp].json` - Detailed results for analysis
- Console output with real-time progress and summary

## âš ï¸ Cost Warning

The detailed test makes many API calls. Monitor your OpenAI usage:
- Quick test: ~24 API calls
- Detailed test: ~300 API calls

Start with the quick test to get a feel for the results!
